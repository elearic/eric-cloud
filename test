



分配分区是怎么样的一个过程

当消费者要加入群组时，它会向群组协调器发送给一个JoinGroup请求，第一个加入群组的消费者将成为"群主"。群主

从协调器那里获得群组的成员列表(列表中包含了所有最近发送过的心跳的消费者，它们被认为是活跃的)，并负责给每一位消费者分配分区。它使用了一个实现了PartitionAssignor接口的类来决定哪些分区应该被分配给哪个消费者。

Kafka内置了两种分配策略，在后面的配置参数小节我们将深入讨论。分配完毕之后，群主把分配情况列表发送给群组协调器，协调器再把这些信息发送给所有消费者。每个消费者只能看到自己的分配信息。只有群主知道群组里所有消费者的分配信息。这个过程会在每次再均衡时重复发生。



消费者的配置

fetch.min.bytes

该属性指定了消费者从服务器获取记录的最小字节数。broker在收到消费者的数据请求时，如果可用的数量小于fetch.min.bytes指定的大小。那么它会等到有足够的可用数据时才把它返回给消费者。这样可以降低消费者和broker的工作负载，因为它们在主题不是很活跃的是时候(或者一天里的低估时段)就不需要来来回回的处理消息。



fetch.max.wait.ms

指定broker的等待时间，默认是500ms。如果没有足够的数据流入Kafka，消费者获取最小数据量的要求就得不到满足，最终导致500ms的延迟。如果要降低潜在的延迟(为了满足SLA)，可以把该参数数值舌质红得小一些。如果fetch.max.wait.ms被设为100ms，并且fetch.min.bytes被设为1MB，那么Kafka在收到消费者的请求后，要么返回1MB数据，要么在100ms后返回所有可用的数据。就看哪个条件先得到满足。



max.artition.fetch.bytes

该属性指定了服务器从每个分区里返回给消费者的最大字节数。它的默认值是1MB，也就是说。KafkaConsumer.poll() 方法从每个分区里返回的记录最多不超过max.partition.fetch.bytes指定的字节。如果一个主题有20个分区和5个消费者，那么每个消费者需要至少4MB的可用内存来接收记录。在为消费者分配内存时，可以给他们多分配一些，因为如果群组里有消费者发生崩溃，剩下的消费者需要处理更多的分区。max.partition.fetch.bytes 的值必须比broker能够接受的最大消息的字节数(通过max.message.size属性配置)大，否则消费者可能无法读取这些消息，导致消费者一直挂起重试。在设置该属性时，另一个需要考虑的因素是消费者处理数据的时间。消费者需要频繁调用poll()方法来避免会话过期发生分区再均衡，如果单次调用poll()返回的数据太多，消费者需要更多的时间来处理，可能无法及时进行下一个轮询来避免会话过期。如果出现这种情况，可以把max.partition.fetch.bytes值改小，或者盐城会话的过期时间



session.timeout.ms

该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间。默认是3s。如果消费者没有在session.time.ms指定的时间没发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，把它的分区分配给群里的其他消费者。该属性与heartbeat.interval.ms紧密相关。herartbeat.interval.ms指定了poll()方法向协调器发送心跳的频率，session.timeout.ms则指定了消费者可以多久不发送心跳。所以，一般需要同时修改这两个属性，heartbeat.interval.ms必须比session.timeout.ms小，一般是session.timeout.ms的三分之一。如果session.timeout.ms是3s。



auto.offset.reset

该属性指定了消费者在读取一个没有偏移量的分区或者偏移量的无效的情况下(因消费者长时间失效，包含偏移量的记录已经过时并被删除)该作何处理。默认值是latest，消费者将从最新的记录开始读取数据(在消费者启动之后生成的记录)。另一个值是earliest，意思是说，在偏移量无效的情况下，消费者姜葱起始位置读取分区的记录。



enable.auto.commit

是否默认提交偏移量，默认值是true。为了避免出现重复数据和数据丢失，可以把它设为false，由自己控制何时提交偏移量。





提交

每次调用poll()方法，它总是返回由生产者写入kafka但

